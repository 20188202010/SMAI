{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './reuters21578/'\n",
    "\n",
    "sgml_number_of_files = 22\n",
    "sgml_file_name_template = 'reut2-NNN.sgm'\n",
    "\n",
    "# Category files\n",
    "category_files = {\n",
    "    'to_': ('Topics', 'all-topics-strings.lc.txt'),\n",
    "    'pl_': ('Places', 'all-places-strings.lc.txt'),\n",
    "    'pe_': ('People', 'all-people-strings.lc.txt'),\n",
    "    'or_': ('Organizations', 'all-orgs-strings.lc.txt'),\n",
    "    'ex_': ('Exchanges', 'all-exchanges-strings.lc.txt')\n",
    "}\n",
    "\n",
    "# Word2Vec number of features\n",
    "num_features = 500\n",
    "# Limit each newsline to a fixed number of words\n",
    "# document_max_num_words = 100\n",
    "# Selected categories\n",
    "# selected_categories = ['pl_usa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['to_acq', 'Topics'],\n",
       " ['to_alum', 'Topics'],\n",
       " ['to_austdlr', 'Topics'],\n",
       " ['to_austral', 'Topics'],\n",
       " ['to_barley', 'Topics'],\n",
       " ['to_bfr', 'Topics'],\n",
       " ['to_bop', 'Topics'],\n",
       " ['to_can', 'Topics'],\n",
       " ['to_carcass', 'Topics'],\n",
       " ['to_castor-meal', 'Topics'],\n",
       " ['to_castor-oil', 'Topics'],\n",
       " ['to_castorseed', 'Topics'],\n",
       " ['to_citruspulp', 'Topics'],\n",
       " ['to_cocoa', 'Topics'],\n",
       " ['to_coconut', 'Topics'],\n",
       " ['to_coconut-oil', 'Topics'],\n",
       " ['to_coffee', 'Topics'],\n",
       " ['to_copper', 'Topics'],\n",
       " ['to_copra-cake', 'Topics'],\n",
       " ['to_corn', 'Topics'],\n",
       " ['to_corn-oil', 'Topics'],\n",
       " ['to_cornglutenfeed', 'Topics'],\n",
       " ['to_cotton', 'Topics'],\n",
       " ['to_cotton-meal', 'Topics'],\n",
       " ['to_cotton-oil', 'Topics'],\n",
       " ['to_cottonseed', 'Topics'],\n",
       " ['to_cpi', 'Topics'],\n",
       " ['to_cpu', 'Topics'],\n",
       " ['to_crude', 'Topics'],\n",
       " ['to_cruzado', 'Topics'],\n",
       " ['to_dfl', 'Topics'],\n",
       " ['to_dkr', 'Topics'],\n",
       " ['to_dlr', 'Topics'],\n",
       " ['to_dmk', 'Topics'],\n",
       " ['to_drachma', 'Topics'],\n",
       " ['to_earn', 'Topics'],\n",
       " ['to_escudo', 'Topics'],\n",
       " ['to_f-cattle', 'Topics'],\n",
       " ['to_ffr', 'Topics'],\n",
       " ['to_fishmeal', 'Topics'],\n",
       " ['to_flaxseed', 'Topics'],\n",
       " ['to_fuel', 'Topics'],\n",
       " ['to_gas', 'Topics'],\n",
       " ['to_gnp', 'Topics'],\n",
       " ['to_gold', 'Topics'],\n",
       " ['to_grain', 'Topics'],\n",
       " ['to_groundnut', 'Topics'],\n",
       " ['to_groundnut-meal', 'Topics'],\n",
       " ['to_groundnut-oil', 'Topics'],\n",
       " ['to_heat', 'Topics'],\n",
       " ['to_hk', 'Topics'],\n",
       " ['to_hog', 'Topics'],\n",
       " ['to_housing', 'Topics'],\n",
       " ['to_income', 'Topics'],\n",
       " ['to_instal-debt', 'Topics'],\n",
       " ['to_interest', 'Topics'],\n",
       " ['to_inventories', 'Topics'],\n",
       " ['to_ipi', 'Topics'],\n",
       " ['to_iron-steel', 'Topics'],\n",
       " ['to_jet', 'Topics'],\n",
       " ['to_jobs', 'Topics'],\n",
       " ['to_l-cattle', 'Topics'],\n",
       " ['to_lead', 'Topics'],\n",
       " ['to_lei', 'Topics'],\n",
       " ['to_lin-meal', 'Topics'],\n",
       " ['to_lin-oil', 'Topics'],\n",
       " ['to_linseed', 'Topics'],\n",
       " ['to_lit', 'Topics'],\n",
       " ['to_livestock', 'Topics'],\n",
       " ['to_lumber', 'Topics'],\n",
       " ['to_lupin', 'Topics'],\n",
       " ['to_meal-feed', 'Topics'],\n",
       " ['to_mexpeso', 'Topics'],\n",
       " ['to_money-fx', 'Topics'],\n",
       " ['to_money-supply', 'Topics'],\n",
       " ['to_naphtha', 'Topics'],\n",
       " ['to_nat-gas', 'Topics'],\n",
       " ['to_nickel', 'Topics'],\n",
       " ['to_nkr', 'Topics'],\n",
       " ['to_nzdlr', 'Topics'],\n",
       " ['to_oat', 'Topics'],\n",
       " ['to_oilseed', 'Topics'],\n",
       " ['to_orange', 'Topics'],\n",
       " ['to_palladium', 'Topics'],\n",
       " ['to_palm-meal', 'Topics'],\n",
       " ['to_palm-oil', 'Topics'],\n",
       " ['to_palmkernel', 'Topics'],\n",
       " ['to_peseta', 'Topics'],\n",
       " ['to_pet-chem', 'Topics'],\n",
       " ['to_platinum', 'Topics'],\n",
       " ['to_plywood', 'Topics'],\n",
       " ['to_pork-belly', 'Topics'],\n",
       " ['to_potato', 'Topics'],\n",
       " ['to_propane', 'Topics'],\n",
       " ['to_rand', 'Topics'],\n",
       " ['to_rape-meal', 'Topics'],\n",
       " ['to_rape-oil', 'Topics'],\n",
       " ['to_rapeseed', 'Topics'],\n",
       " ['to_red-bean', 'Topics'],\n",
       " ['to_reserves', 'Topics'],\n",
       " ['to_retail', 'Topics'],\n",
       " ['to_rice', 'Topics'],\n",
       " ['to_ringgit', 'Topics'],\n",
       " ['to_rubber', 'Topics'],\n",
       " ['to_rupiah', 'Topics'],\n",
       " ['to_rye', 'Topics'],\n",
       " ['to_saudriyal', 'Topics'],\n",
       " ['to_sfr', 'Topics'],\n",
       " ['to_ship', 'Topics'],\n",
       " ['to_silk', 'Topics'],\n",
       " ['to_silver', 'Topics'],\n",
       " ['to_singdlr', 'Topics'],\n",
       " ['to_skr', 'Topics'],\n",
       " ['to_sorghum', 'Topics'],\n",
       " ['to_soy-meal', 'Topics'],\n",
       " ['to_soy-oil', 'Topics'],\n",
       " ['to_soybean', 'Topics'],\n",
       " ['to_stg', 'Topics'],\n",
       " ['to_strategic-metal', 'Topics'],\n",
       " ['to_sugar', 'Topics'],\n",
       " ['to_sun-meal', 'Topics'],\n",
       " ['to_sun-oil', 'Topics'],\n",
       " ['to_sunseed', 'Topics'],\n",
       " ['to_tapioca', 'Topics'],\n",
       " ['to_tea', 'Topics'],\n",
       " ['to_tin', 'Topics'],\n",
       " ['to_trade', 'Topics'],\n",
       " ['to_tung', 'Topics'],\n",
       " ['to_tung-oil', 'Topics'],\n",
       " ['to_veg-oil', 'Topics'],\n",
       " ['to_wheat', 'Topics'],\n",
       " ['to_wool', 'Topics'],\n",
       " ['to_wpi', 'Topics'],\n",
       " ['to_yen', 'Topics'],\n",
       " ['to_zinc', 'Topics'],\n",
       " ['pl_afghanistan', 'Places'],\n",
       " ['pl_albania', 'Places'],\n",
       " ['pl_algeria', 'Places'],\n",
       " ['pl_american-samoa', 'Places'],\n",
       " ['pl_andorra', 'Places'],\n",
       " ['pl_angola', 'Places'],\n",
       " ['pl_anguilla', 'Places'],\n",
       " ['pl_antigua', 'Places'],\n",
       " ['pl_argentina', 'Places'],\n",
       " ['pl_aruba', 'Places'],\n",
       " ['pl_australia', 'Places'],\n",
       " ['pl_austria', 'Places'],\n",
       " ['pl_bahamas', 'Places'],\n",
       " ['pl_bahrain', 'Places'],\n",
       " ['pl_bangladesh', 'Places'],\n",
       " ['pl_barbados', 'Places'],\n",
       " ['pl_belgium', 'Places'],\n",
       " ['pl_belize', 'Places'],\n",
       " ['pl_benin', 'Places'],\n",
       " ['pl_bermuda', 'Places'],\n",
       " ['pl_bhutan', 'Places'],\n",
       " ['pl_bolivia', 'Places'],\n",
       " ['pl_botswana', 'Places'],\n",
       " ['pl_brazil', 'Places'],\n",
       " ['pl_british-virgin-islands', 'Places'],\n",
       " ['pl_brunei', 'Places'],\n",
       " ['pl_bulgaria', 'Places'],\n",
       " ['pl_burkina-faso', 'Places'],\n",
       " ['pl_burma', 'Places'],\n",
       " ['pl_burundi', 'Places'],\n",
       " ['pl_cameroon', 'Places'],\n",
       " ['pl_canada', 'Places'],\n",
       " ['pl_cape-verde', 'Places'],\n",
       " ['pl_cayman-islands', 'Places'],\n",
       " ['pl_central-african-republic', 'Places'],\n",
       " ['pl_chad', 'Places'],\n",
       " ['pl_chile', 'Places'],\n",
       " ['pl_china', 'Places'],\n",
       " ['pl_colombia', 'Places'],\n",
       " ['pl_congo', 'Places'],\n",
       " ['pl_costa-rica', 'Places'],\n",
       " ['pl_cuba', 'Places'],\n",
       " ['pl_cyprus', 'Places'],\n",
       " ['pl_czechoslovakia', 'Places'],\n",
       " ['pl_denmark', 'Places'],\n",
       " ['pl_djibouti', 'Places'],\n",
       " ['pl_dominica', 'Places'],\n",
       " ['pl_dominican-republic', 'Places'],\n",
       " ['pl_east-germany', 'Places'],\n",
       " ['pl_ecuador', 'Places'],\n",
       " ['pl_egypt', 'Places'],\n",
       " ['pl_el-salvador', 'Places'],\n",
       " ['pl_equatorial-guinea', 'Places'],\n",
       " ['pl_ethiopia', 'Places'],\n",
       " ['pl_fiji', 'Places'],\n",
       " ['pl_finland', 'Places'],\n",
       " ['pl_france', 'Places'],\n",
       " ['pl_french-guiana', 'Places'],\n",
       " ['pl_gabon', 'Places'],\n",
       " ['pl_gambia', 'Places'],\n",
       " ['pl_ghana', 'Places'],\n",
       " ['pl_gibraltar', 'Places'],\n",
       " ['pl_greece', 'Places'],\n",
       " ['pl_grenada', 'Places'],\n",
       " ['pl_guadeloupe', 'Places'],\n",
       " ['pl_guam', 'Places'],\n",
       " ['pl_guatemala', 'Places'],\n",
       " ['pl_guinea', 'Places'],\n",
       " ['pl_guinea-bissau', 'Places'],\n",
       " ['pl_guyana', 'Places'],\n",
       " ['pl_haiti', 'Places'],\n",
       " ['pl_honduras', 'Places'],\n",
       " ['pl_hong-kong', 'Places'],\n",
       " ['pl_hungary', 'Places'],\n",
       " ['pl_iceland', 'Places'],\n",
       " ['pl_india', 'Places'],\n",
       " ['pl_indonesia', 'Places'],\n",
       " ['pl_iran', 'Places'],\n",
       " ['pl_iraq', 'Places'],\n",
       " ['pl_ireland', 'Places'],\n",
       " ['pl_israel', 'Places'],\n",
       " ['pl_italy', 'Places'],\n",
       " ['pl_ivory-coast', 'Places'],\n",
       " ['pl_jamaica', 'Places'],\n",
       " ['pl_japan', 'Places'],\n",
       " ['pl_jordan', 'Places'],\n",
       " ['pl_kampuchea', 'Places'],\n",
       " ['pl_kenya', 'Places'],\n",
       " ['pl_kuwait', 'Places'],\n",
       " ['pl_laos', 'Places'],\n",
       " ['pl_lebanon', 'Places'],\n",
       " ['pl_lesotho', 'Places'],\n",
       " ['pl_liberia', 'Places'],\n",
       " ['pl_libya', 'Places'],\n",
       " ['pl_liechtenstein', 'Places'],\n",
       " ['pl_luxembourg', 'Places'],\n",
       " ['pl_macao', 'Places'],\n",
       " ['pl_madagascar', 'Places'],\n",
       " ['pl_malawi', 'Places'],\n",
       " ['pl_malaysia', 'Places'],\n",
       " ['pl_mali', 'Places'],\n",
       " ['pl_malta', 'Places'],\n",
       " ['pl_martinique', 'Places'],\n",
       " ['pl_mauritania', 'Places'],\n",
       " ['pl_mauritius', 'Places'],\n",
       " ['pl_mexico', 'Places'],\n",
       " ['pl_monaco', 'Places'],\n",
       " ['pl_morocco', 'Places'],\n",
       " ['pl_mozambique', 'Places'],\n",
       " ['pl_namibia', 'Places'],\n",
       " ['pl_nepal', 'Places'],\n",
       " ['pl_netherlands', 'Places'],\n",
       " ['pl_netherlands-antilles', 'Places'],\n",
       " ['pl_new-caledonia', 'Places'],\n",
       " ['pl_new-zealand', 'Places'],\n",
       " ['pl_nicaragua', 'Places'],\n",
       " ['pl_niger', 'Places'],\n",
       " ['pl_nigeria', 'Places'],\n",
       " ['pl_north-korea', 'Places'],\n",
       " ['pl_norway', 'Places'],\n",
       " ['pl_oman', 'Places'],\n",
       " ['pl_pakistan', 'Places'],\n",
       " ['pl_panama', 'Places'],\n",
       " ['pl_papua-new-guinea', 'Places'],\n",
       " ['pl_paraguay', 'Places'],\n",
       " ['pl_peru', 'Places'],\n",
       " ['pl_philippines', 'Places'],\n",
       " ['pl_poland', 'Places'],\n",
       " ['pl_portugal', 'Places'],\n",
       " ['pl_qatar', 'Places'],\n",
       " ['pl_romania', 'Places'],\n",
       " ['pl_rwanda', 'Places'],\n",
       " ['pl_saudi-arabia', 'Places'],\n",
       " ['pl_senegal', 'Places'],\n",
       " ['pl_seychelles', 'Places'],\n",
       " ['pl_sierra-leone', 'Places'],\n",
       " ['pl_singapore', 'Places'],\n",
       " ['pl_somalia', 'Places'],\n",
       " ['pl_south-africa', 'Places'],\n",
       " ['pl_south-korea', 'Places'],\n",
       " ['pl_spain', 'Places'],\n",
       " ['pl_sri-lanka', 'Places'],\n",
       " ['pl_sudan', 'Places'],\n",
       " ['pl_suriname', 'Places'],\n",
       " ['pl_swaziland', 'Places'],\n",
       " ['pl_sweden', 'Places'],\n",
       " ['pl_switzerland', 'Places'],\n",
       " ['pl_syria', 'Places'],\n",
       " ['pl_taiwan', 'Places'],\n",
       " ['pl_tanzania', 'Places'],\n",
       " ['pl_thailand', 'Places'],\n",
       " ['pl_togo', 'Places'],\n",
       " ['pl_tonga', 'Places'],\n",
       " ['pl_trinidad-tobago', 'Places'],\n",
       " ['pl_tunisia', 'Places'],\n",
       " ['pl_turkey', 'Places'],\n",
       " ['pl_uae', 'Places'],\n",
       " ['pl_uganda', 'Places'],\n",
       " ['pl_uk', 'Places'],\n",
       " ['pl_uruguay', 'Places'],\n",
       " ['pl_us-virgin-islands', 'Places'],\n",
       " ['pl_usa', 'Places'],\n",
       " ['pl_ussr', 'Places'],\n",
       " ['pl_vanuatu', 'Places'],\n",
       " ['pl_vatican', 'Places'],\n",
       " ['pl_venezuela', 'Places'],\n",
       " ['pl_vietnam', 'Places'],\n",
       " ['pl_west-germany', 'Places'],\n",
       " ['pl_western-samoa', 'Places'],\n",
       " ['pl_yemen-arab-republic', 'Places'],\n",
       " ['pl_yemen-demo-republic', 'Places'],\n",
       " ['pl_yugoslavia', 'Places'],\n",
       " ['pl_zaire', 'Places'],\n",
       " ['pl_zambia', 'Places'],\n",
       " ['pl_zimbabwe', 'Places'],\n",
       " ['pe_abdel-hadi-kandeel', 'People'],\n",
       " ['pe_alfonsin', 'People'],\n",
       " ['pe_alhaji-abdul-ahmed', 'People'],\n",
       " ['pe_alptemocin', 'People'],\n",
       " ['pe_amato', 'People'],\n",
       " ['pe_andersen', 'People'],\n",
       " ['pe_andriessen', 'People'],\n",
       " ['pe_aqazadeh', 'People'],\n",
       " ['pe_aquino', 'People'],\n",
       " ['pe_arafat', 'People'],\n",
       " ['pe_babangida', 'People'],\n",
       " ['pe_balladur', 'People'],\n",
       " ['pe_bangemann', 'People'],\n",
       " ['pe_barreto', 'People'],\n",
       " ['pe_berge', 'People'],\n",
       " ['pe_beteta', 'People'],\n",
       " ['pe_blix', 'People'],\n",
       " ['pe_boesky', 'People'],\n",
       " ['pe_bond', 'People'],\n",
       " ['pe_botha', 'People'],\n",
       " ['pe_bouey', 'People'],\n",
       " ['pe_braks', 'People'],\n",
       " ['pe_bresser-pereira', 'People'],\n",
       " ['pe_brodersohn', 'People'],\n",
       " ['pe_brundtland', 'People'],\n",
       " ['pe_camdessus', 'People'],\n",
       " ['pe_carlsson', 'People'],\n",
       " ['pe_caro', 'People'],\n",
       " ['pe_castelo-branco', 'People'],\n",
       " ['pe_castro', 'People'],\n",
       " ['pe_cavaco-silva', 'People'],\n",
       " ['pe_chaves', 'People'],\n",
       " ['pe_chen-muhua', 'People'],\n",
       " ['pe_chiang-ching-kuo', 'People'],\n",
       " ['pe_chien', 'People'],\n",
       " ['pe_chirac', 'People'],\n",
       " ['pe_ciampi', 'People'],\n",
       " ['pe_colombo', 'People'],\n",
       " ['pe_conable', 'People'],\n",
       " ['pe_concepcion', 'People'],\n",
       " ['pe_corrigan', 'People'],\n",
       " ['pe_cossiga', 'People'],\n",
       " ['pe_crow', 'People'],\n",
       " ['pe_dadzie', 'People'],\n",
       " ['pe_dauster', 'People'],\n",
       " ['pe_de-clercq', 'People'],\n",
       " ['pe_de-kock', 'People'],\n",
       " ['pe_de-korte', 'People'],\n",
       " ['pe_de-la-madrid', 'People'],\n",
       " ['pe_de-larosiere', 'People'],\n",
       " ['pe_del-mazo', 'People'],\n",
       " ['pe_delamuraz', 'People'],\n",
       " ['pe_delors', 'People'],\n",
       " ['pe_dementsev', 'People'],\n",
       " ['pe_deng-xiaoping', 'People'],\n",
       " ['pe_dennis', 'People'],\n",
       " ['pe_dhillon', 'People'],\n",
       " ['pe_dominguez', 'People'],\n",
       " ['pe_douglas', 'People'],\n",
       " ['pe_du-plessis', 'People'],\n",
       " ['pe_duisenberg', 'People'],\n",
       " ['pe_dunkel', 'People'],\n",
       " ['pe_edelman', 'People'],\n",
       " ['pe_enggaard', 'People'],\n",
       " ['pe_eser', 'People'],\n",
       " ['pe_evren', 'People'],\n",
       " ['pe_eyskens', 'People'],\n",
       " ['pe_feldt', 'People'],\n",
       " ['pe_fernandez', 'People'],\n",
       " ['pe_ferrari', 'People'],\n",
       " ['pe_finnbogadottir', 'People'],\n",
       " ['pe_friedman', 'People'],\n",
       " ['pe_fujioka', 'People'],\n",
       " ['pe_gaddafi', 'People'],\n",
       " ['pe_gandhi', 'People'],\n",
       " ['pe_garcia', 'People'],\n",
       " ['pe_gava', 'People'],\n",
       " ['pe_godeaux', 'People'],\n",
       " ['pe_gonzalez', 'People'],\n",
       " ['pe_gorbachev', 'People'],\n",
       " ['pe_goria', 'People'],\n",
       " ['pe_gostyev', 'People'],\n",
       " ['pe_graf', 'People'],\n",
       " ['pe_greenspan', 'People'],\n",
       " ['pe_gromyko', 'People'],\n",
       " ['pe_grosz', 'People'],\n",
       " ['pe_guillaume', 'People'],\n",
       " ['pe_halikias', 'People'],\n",
       " ['pe_hamad-saud-al-sayyari', 'People'],\n",
       " ['pe_hannibalsson', 'People'],\n",
       " ['pe_haughey', 'People'],\n",
       " ['pe_hawke', 'People'],\n",
       " ['pe_he-kang', 'People'],\n",
       " ['pe_herrington', 'People'],\n",
       " ['pe_hillery', 'People'],\n",
       " ['pe_hisham-nazer', 'People'],\n",
       " ['pe_hoefner', 'People'],\n",
       " ['pe_hoffmeyer', 'People'],\n",
       " ['pe_holberg', 'People'],\n",
       " ['pe_holkeri', 'People'],\n",
       " ['pe_honecker', 'People'],\n",
       " ['pe_hovmand', 'People'],\n",
       " ['pe_howard-baker', 'People'],\n",
       " ['pe_husak', 'People'],\n",
       " ['pe_icahn', 'People'],\n",
       " ['pe_james-baker', 'People'],\n",
       " ['pe_james-miller', 'People'],\n",
       " ['pe_jaruzelski', 'People'],\n",
       " ['pe_jayme', 'People'],\n",
       " ['pe_johnston', 'People'],\n",
       " ['pe_kaminsky', 'People'],\n",
       " ['pe_kaufman', 'People'],\n",
       " ['pe_keating', 'People'],\n",
       " ['pe_khameini', 'People'],\n",
       " ['pe_khomeini', 'People'],\n",
       " ['pe_kiechle', 'People'],\n",
       " ['pe_king-fahd', 'People'],\n",
       " ['pe_kohl', 'People'],\n",
       " ['pe_koivisto', 'People'],\n",
       " ['pe_kondo', 'People'],\n",
       " ['pe_koren', 'People'],\n",
       " ['pe_kullberg', 'People'],\n",
       " ['pe_lacina', 'People'],\n",
       " ['pe_lange', 'People'],\n",
       " ['pe_languetin', 'People'],\n",
       " ['pe_lawson', 'People'],\n",
       " ['pe_lee-ta-hai', 'People'],\n",
       " ['pe_lee-teng-hui', 'People'],\n",
       " ['pe_leenanon', 'People'],\n",
       " ['pe_leigh-pemberton', 'People'],\n",
       " ['pe_leitz', 'People'],\n",
       " ['pe_li-peng', 'People'],\n",
       " ['pe_li-xiannian', 'People'],\n",
       " ['pe_liikanen', 'People'],\n",
       " ['pe_lubbers', 'People'],\n",
       " ['pe_lukman', 'People'],\n",
       " ['pe_lyng', 'People'],\n",
       " ['pe_machinea', 'People'],\n",
       " ['pe_macsharry', 'People'],\n",
       " ['pe_malhotra', 'People'],\n",
       " ['pe_mancera-aguayo', 'People'],\n",
       " ['pe_martens', 'People'],\n",
       " ['pe_martin', 'People'],\n",
       " ['pe_masse', 'People'],\n",
       " ['pe_maxwell', 'People'],\n",
       " ['pe_maystadt', 'People'],\n",
       " ['pe_medgyessy', 'People'],\n",
       " ['pe_messner', 'People'],\n",
       " ['pe_mikulic', 'People'],\n",
       " ['pe_milliet', 'People'],\n",
       " ['pe_mitterrand', 'People'],\n",
       " ['pe_miyazawa', 'People'],\n",
       " ['pe_mohammad-ibrahim-jaffrey-baluch', 'People'],\n",
       " ['pe_mohammad-khan-junejo', 'People'],\n",
       " ['pe_mohammad-yasin-khan-wattoo', 'People'],\n",
       " ['pe_mohammed-ahmed-al-razaz', 'People'],\n",
       " ['pe_mohammed-ali-abal-khail', 'People'],\n",
       " ['pe_mohammed-salaheddin-hamid', 'People'],\n",
       " ['pe_morales-bermudez', 'People'],\n",
       " ['pe_mousavi', 'People'],\n",
       " ['pe_moyle', 'People'],\n",
       " ['pe_mubarak', 'People'],\n",
       " ['pe_mulroney', 'People'],\n",
       " ['pe_murdoch', 'People'],\n",
       " ['pe_mustapha', 'People'],\n",
       " ['pe_nakao', 'People'],\n",
       " ['pe_nakasone', 'People'],\n",
       " ['pe_nasko', 'People'],\n",
       " ['pe_nemeth', 'People'],\n",
       " ['pe_nobrega', 'People'],\n",
       " ['pe_o-cofaigh', 'People'],\n",
       " ['pe_o-kennedy', 'People'],\n",
       " ['pe_oeien', 'People'],\n",
       " ['pe_okongwu', 'People'],\n",
       " ['pe_ongpin', 'People'],\n",
       " ['pe_ortega', 'People'],\n",
       " ['pe_ozal', 'People'],\n",
       " ['pe_palsson', 'People'],\n",
       " ['pe_pandolfi', 'People'],\n",
       " ['pe_papandreou', 'People'],\n",
       " ['pe_parkinson', 'People'],\n",
       " ['pe_paye', 'People'],\n",
       " ['pe_perez-de-cuellar', 'People'],\n",
       " ['pe_petricioli', 'People'],\n",
       " ['pe_pickens', 'People'],\n",
       " ['pe_poehl', 'People'],\n",
       " ['pe_pottakis', 'People'],\n",
       " ['pe_prawiro', 'People'],\n",
       " ['pe_qassemi', 'People'],\n",
       " ['pe_rafnar', 'People'],\n",
       " ['pe_rafsanjani', 'People'],\n",
       " ['pe_reagan', 'People'],\n",
       " ['pe_rezende', 'People'],\n",
       " ['pe_riberio-cadilhe', 'People'],\n",
       " ['pe_rich', 'People'],\n",
       " ['pe_rikanovic', 'People'],\n",
       " ['pe_rojas', 'People'],\n",
       " ['pe_romero', 'People'],\n",
       " ['pe_roumeliotis', 'People'],\n",
       " ['pe_rowland', 'People'],\n",
       " ['pe_rubio', 'People'],\n",
       " ['pe_ruder', 'People'],\n",
       " ['pe_ruding', 'People'],\n",
       " ['pe_russell', 'People'],\n",
       " ['pe_ryzhkov', 'People'],\n",
       " ['pe_saberbein', 'People'],\n",
       " ['pe_salinas', 'People'],\n",
       " ['pe_samojlik', 'People'],\n",
       " ['pe_santer', 'People'],\n",
       " ['pe_saracoglu', 'People'],\n",
       " ['pe_sarney', 'People'],\n",
       " ['pe_sartzetakis', 'People'],\n",
       " ['pe_sathe', 'People'],\n",
       " ['pe_schlueter', 'People'],\n",
       " ['pe_sedki', 'People'],\n",
       " ['pe_simitis', 'People'],\n",
       " ['pe_simonsen', 'People'],\n",
       " ['pe_singhasaneh', 'People'],\n",
       " ['pe_siregar', 'People'],\n",
       " ['pe_skaanland', 'People'],\n",
       " ['pe_soares', 'People'],\n",
       " ['pe_solchaga', 'People'],\n",
       " ['pe_sourrouille', 'People'],\n",
       " ['pe_sprinkel', 'People'],\n",
       " ['pe_steeg', 'People'],\n",
       " ['pe_stich', 'People'],\n",
       " ['pe_stoltenberg', 'People'],\n",
       " ['pe_stoph', 'People'],\n",
       " ['pe_strougal', 'People'],\n",
       " ['pe_subroto', 'People'],\n",
       " ['pe_suharto', 'People'],\n",
       " ['pe_sumita', 'People'],\n",
       " ['pe_suominen', 'People'],\n",
       " ['pe_takeshita', 'People'],\n",
       " ['pe_tamura', 'People'],\n",
       " ['pe_tavares-moreia', 'People'],\n",
       " ['pe_thatcher', 'People'],\n",
       " ['pe_timar', 'People'],\n",
       " ['pe_tinsulanonda', 'People'],\n",
       " ['pe_tiwari', 'People'],\n",
       " ['pe_toernaes', 'People'],\n",
       " ['pe_toman', 'People'],\n",
       " ['pe_tsovolas', 'People'],\n",
       " ['pe_vancsa', 'People'],\n",
       " ['pe_venkataraman', 'People'],\n",
       " ['pe_vera-la-rosa', 'People'],\n",
       " ['pe_verity', 'People'],\n",
       " ['pe_villanyi', 'People'],\n",
       " ['pe_vlatkovic', 'People'],\n",
       " ['pe_volcker', 'People'],\n",
       " ['pe_von-weizsaecker', 'People'],\n",
       " ['pe_vranitzky', 'People'],\n",
       " ['pe_waldheim', 'People'],\n",
       " ['pe_wali', 'People'],\n",
       " ['pe_walsh', 'People'],\n",
       " ['pe_wang-bingqian', 'People'],\n",
       " ['pe_wardhana', 'People'],\n",
       " ['pe_wasim-aun-jaffrey', 'People'],\n",
       " ['pe_wilson', 'People'],\n",
       " ['pe_wise', 'People'],\n",
       " ['pe_yeutter', 'People'],\n",
       " ['pe_young', 'People'],\n",
       " ['pe_yu-kuo-hua', 'People'],\n",
       " ['pe_zak', 'People'],\n",
       " ['pe_zhao-ziyang', 'People'],\n",
       " ['pe_zheng-tuobin', 'People'],\n",
       " ['pe_zia-ul-haq', 'People'],\n",
       " ['or_adb-africa', 'Organizations'],\n",
       " ['or_adb-asia', 'Organizations'],\n",
       " ['or_aibd', 'Organizations'],\n",
       " ['or_aid', 'Organizations'],\n",
       " ['or_anrpc', 'Organizations'],\n",
       " ['or_asean', 'Organizations'],\n",
       " ['or_atpc', 'Organizations'],\n",
       " ['or_bis', 'Organizations'],\n",
       " ['or_cipec', 'Organizations'],\n",
       " ['or_comecon', 'Organizations'],\n",
       " ['or_ec', 'Organizations'],\n",
       " ['or_eca', 'Organizations'],\n",
       " ['or_ecafe', 'Organizations'],\n",
       " ['or_ece', 'Organizations'],\n",
       " ['or_ecla', 'Organizations'],\n",
       " ['or_ecsc', 'Organizations'],\n",
       " ['or_ecwa', 'Organizations'],\n",
       " ['or_efta', 'Organizations'],\n",
       " ['or_eib', 'Organizations'],\n",
       " ['or_emcf', 'Organizations'],\n",
       " ['or_escap', 'Organizations'],\n",
       " ['or_euratom', 'Organizations'],\n",
       " ['or_fao', 'Organizations'],\n",
       " ['or_gatt', 'Organizations'],\n",
       " ['or_gcc', 'Organizations'],\n",
       " ['or_geplacea', 'Organizations'],\n",
       " ['or_iaea', 'Organizations'],\n",
       " ['or_iata', 'Organizations'],\n",
       " ['or_icco', 'Organizations'],\n",
       " ['or_ico-coffee', 'Organizations'],\n",
       " ['or_ico-islam', 'Organizations'],\n",
       " ['or_ida', 'Organizations'],\n",
       " ['or_iea', 'Organizations'],\n",
       " ['or_iisi', 'Organizations'],\n",
       " ['or_ilo', 'Organizations'],\n",
       " ['or_ilzsg', 'Organizations'],\n",
       " ['or_imco', 'Organizations'],\n",
       " ['or_imf', 'Organizations'],\n",
       " ['or_inro', 'Organizations'],\n",
       " ['or_irsg', 'Organizations'],\n",
       " ['or_isa', 'Organizations'],\n",
       " ['or_itc', 'Organizations'],\n",
       " ['or_iwc-whale', 'Organizations'],\n",
       " ['or_iwc-wheat', 'Organizations'],\n",
       " ['or_iwcc', 'Organizations'],\n",
       " ['or_iws', 'Organizations'],\n",
       " ['or_iwto', 'Organizations'],\n",
       " ['or_lafta', 'Organizations'],\n",
       " ['or_mfa', 'Organizations'],\n",
       " ['or_oapec', 'Organizations'],\n",
       " ['or_oecd', 'Organizations'],\n",
       " ['or_opec', 'Organizations'],\n",
       " ['or_un', 'Organizations'],\n",
       " ['or_unctad', 'Organizations'],\n",
       " ['or_who', 'Organizations'],\n",
       " ['or_worldbank', 'Organizations'],\n",
       " ['ex_amex', 'Exchanges'],\n",
       " ['ex_ase', 'Exchanges'],\n",
       " ['ex_asx', 'Exchanges'],\n",
       " ['ex_biffex', 'Exchanges'],\n",
       " ['ex_bse', 'Exchanges'],\n",
       " ['ex_cboe', 'Exchanges'],\n",
       " ['ex_cbt', 'Exchanges'],\n",
       " ['ex_cme', 'Exchanges'],\n",
       " ['ex_comex', 'Exchanges'],\n",
       " ['ex_cse', 'Exchanges'],\n",
       " ['ex_fox', 'Exchanges'],\n",
       " ['ex_fse', 'Exchanges'],\n",
       " ['ex_hkse', 'Exchanges'],\n",
       " ['ex_ipe', 'Exchanges'],\n",
       " ['ex_jse', 'Exchanges'],\n",
       " ['ex_klce', 'Exchanges'],\n",
       " ['ex_klse', 'Exchanges'],\n",
       " ['ex_liffe', 'Exchanges'],\n",
       " ['ex_lme', 'Exchanges'],\n",
       " ['ex_lse', 'Exchanges'],\n",
       " ['ex_mase', 'Exchanges'],\n",
       " ['ex_mise', 'Exchanges'],\n",
       " ['ex_mnse', 'Exchanges'],\n",
       " ['ex_mose', 'Exchanges'],\n",
       " ['ex_nasdaq', 'Exchanges'],\n",
       " ['ex_nyce', 'Exchanges'],\n",
       " ['ex_nycsce', 'Exchanges'],\n",
       " ['ex_nymex', 'Exchanges'],\n",
       " ['ex_nyse', 'Exchanges'],\n",
       " ['ex_ose', 'Exchanges'],\n",
       " ['ex_pse', 'Exchanges'],\n",
       " ['ex_set', 'Exchanges'],\n",
       " ['ex_simex', 'Exchanges'],\n",
       " ['ex_sse', 'Exchanges'],\n",
       " ['ex_stse', 'Exchanges'],\n",
       " ['ex_tose', 'Exchanges'],\n",
       " ['ex_tse', 'Exchanges'],\n",
       " ['ex_wce', 'Exchanges'],\n",
       " ['ex_zse', 'Exchanges']]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create category dataframe\n",
    "\n",
    "# Read all categories\n",
    "category_data = []\n",
    "\n",
    "for category_prefix in category_files.keys():\n",
    "    with open(data_folder + category_files[category_prefix][1], 'r') as file:\n",
    "        for category in file.readlines():\n",
    "            category_data.append([category_prefix + category.strip().lower(), \n",
    "                                  category_files[category_prefix][0]])\n",
    "\n",
    "# Create category dataframe\n",
    "news_categories = pd.DataFrame(data=category_data)\n",
    "\n",
    "# print \"category_data: \", category_data\n",
    "(news_categories.values).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sarvat/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import xml.sax.saxutils as saxutils\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_category_vector(categories):\n",
    "    vector = zeros(len(categories)).astype(float32)\n",
    "    \n",
    "    for i in range(len(categories)):\n",
    "        if target_categories[i] in categories:\n",
    "            vector[i] = 1.0\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "strip_special_chars = re.compile(\"[^A-Za-z0-9 ]+\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def cleanUpSentence(r, stop_words = None):\n",
    "    r = r.lower().replace(\"<br />\", \" \")\n",
    "    r = re.sub(strip_special_chars, \"\", r.lower())\n",
    "    if stop_words is not None:\n",
    "        words = word_tokenize(r)\n",
    "        filtered_sentence = []\n",
    "        for w in words:\n",
    "            w = lemmatizer.lemmatize(w)\n",
    "            if w not in stop_words:\n",
    "                filtered_sentence.append(w)\n",
    "        return \" \".join(filtered_sentence)\n",
    "    else:\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5)\n"
     ]
    }
   ],
   "source": [
    "# Parse SGML files\n",
    "document_X = {}\n",
    "document_Y = {}\n",
    "docid_traintest = {}\n",
    "def strip_tags(text):\n",
    "    return re.sub('<[^<]+?>', '', text).strip()\n",
    "\n",
    "def unescape(text):\n",
    "    return saxutils.unescape(text)\n",
    "\n",
    "# Iterate all files\n",
    "# for i in range(sgml_number_of_files):\n",
    "#     if i < 10:\n",
    "#         seq = '00' + str(i)\n",
    "#     else:\n",
    "#         seq = '0' + str(i)\n",
    "        \n",
    "#     file_name = sgml_file_name_template.replace('NNN', seq)\n",
    "#     print('Reading file: %s' % file_name)\n",
    "    #data_folder + file_name\n",
    "with open(data_folder+'reut2-000.sgm', 'rb') as file:\n",
    "    \n",
    "    content = BeautifulSoup(file.read().lower(),'html.parser')\n",
    "\n",
    "    for newsline in content('reuters'):\n",
    "        document_categories = []\n",
    "\n",
    "        # News-line Id\n",
    "        document_id = newsline['newid']\n",
    "#             print document_id,\n",
    "        train_test = newsline['lewissplit']\n",
    "        docid_traintest[document_id] = train_test\n",
    "#             print \"train_test: \",train_test\n",
    "\n",
    "        # News-line text\n",
    "        document_body = strip_tags(str(newsline('text')[0].body)).replace('reuter\\n&#3;', '')\n",
    "        doc_categories=strip_tags(str(newsline('topics')[0].body))\n",
    "        doc_categories = unescape(doc_categories)\n",
    "\n",
    "        document_body = unescape(document_body)\n",
    "\n",
    "        # News-line categories\n",
    "        topics = newsline.topics.contents\n",
    "        places = newsline.places.contents\n",
    "        people = newsline.people.contents\n",
    "        orgs = newsline.orgs.contents\n",
    "        exchanges = newsline.exchanges.contents\n",
    "\n",
    "        for topic in topics:\n",
    "            document_categories.append('to_' + strip_tags(str(topic)))\n",
    "\n",
    "        for place in places:\n",
    "            document_categories.append('pl_' + strip_tags(str(place)))\n",
    "\n",
    "        for person in people:\n",
    "            document_categories.append('pe_' + strip_tags(str(person)))\n",
    "\n",
    "        for org in orgs:\n",
    "            document_categories.append('or_' + strip_tags(str(org)))\n",
    "\n",
    "        for exchange in exchanges:\n",
    "            document_categories.append('ex_' + strip_tags(str(exchange)))\n",
    "#             print \"document_categories: \",document_categories\n",
    "        # Create new document    \n",
    "#             update_frequencies(document_categories)\n",
    "\n",
    "        document_X[document_id] = document_body\n",
    "        document_Y[document_id] = document_categories\n",
    "# print(document_Y)\n",
    "one_hot_label=[]\n",
    "for key,v in document_Y.items():\n",
    "    dict_temp={'Topics':0,'Places':0,'Peoples':0,'Exchanges':0,'Organizations':0}\n",
    "    for i in v:\n",
    "        string=i.split('_')\n",
    "        category=string[0]\n",
    "        if category=='to':\n",
    "            dict_temp['Topics']+=1\n",
    "        if category=='pl':\n",
    "            dict_temp['Places']+=1\n",
    "        if category=='ex':\n",
    "            dict_temp['Exchanges']+=1\n",
    "        if category=='or':\n",
    "            dict_temp['Organizations']+=1\n",
    "        if category=='pe':\n",
    "            dict_temp['Peoples']+=1\n",
    "    one_hot_label.append(dict_temp)\n",
    "    \n",
    "# print(one_hot_label)\n",
    "ranking=[]\n",
    "for i in one_hot_label:\n",
    "    ranking.append(list(i.values()))\n",
    "print(np.array(ranking).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sarvat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/sarvat/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shower continued throughout week inthe bahia cocoa zone alleviating drought since earlyjanuary improving prospect coming temporaoalthough normal humidity level restoredcomissaria smith said weekly review dry period mean temporao late year arrival week ended february 22 155221 bagsof 60 kilo making cumulative total season 593mln 581 stage last year seemsthat cocoa delivered earlier consignment wa included thearrivals figure comissaria smith said still doubt howmuch old crop cocoa still available harvesting haspractically come end total bahia crop estimatesaround 64 mln bag sale standing almost 62 mln thereare hundred thousand bag still hand farmersmiddlemen exporter processor doubt much cocoa would fitfor export shipper experiencing dificulties inobtaining bahia superior certificate view lower quality recent week farmer havesold good part cocoa held consignment comissaria smith said spot bean price rose 340 350cruzados per arroba 15 kilo bean shipper reluctant offer nearby shipment andonly limited sale booked march shipment 1750 to1780 dlrs per tonne port named new crop sale also light open port withjunejuly going 1850 1880 dlrs 35 45 dlrsunder new york july augsept 1870 1875 1880 dlrsper tonne fob routine sale butter made marchapril sold at4340 4345 4350 dlrs aprilmay butter went 227 time new york may junejulyat 4400 4415 dlrs augsept 4351 4450 dlrs at227 228 time new york sept octdec 4480 dlrs and227 time new york dec comissaria smith said destination u covertible currency areasuruguay open port cake sale registered 785 995 dlrs formarchapril 785 dlrs may 753 dlrs aug 039 timesnew york dec octdec buyer u argentina uruguay convertiblecurrency area liquor sale limited marchapril selling 2325and 2380 dlrs junejuly 2375 dlrs 125 time newyork july augsept 2400 dlrs 125 time new yorksept octdec 125 time new york dec comissaria smithsaid total bahia sale currently estimated 613 mln bagsagainst 198687 crop 106 mln bag 198788crop final figure period february 28 expected tobe published brazilian cocoa trade commission aftercarnival end midday february 27 reuter\n"
     ]
    }
   ],
   "source": [
    "totalX = []\n",
    "#totalY = np.array(document_Y)\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "#print(document_X.keys())\n",
    "for i, doc in document_X.items():\n",
    "    #print(i)\n",
    "    totalX.append(cleanUpSentence(doc, stop_words))\n",
    "\n",
    "\n",
    "print(totalX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 17601)\n",
      "input_vocab_size: 17601\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "max_vocab_size = 200\n",
    "input_tokenizer = Tokenizer()# change accuracy....\n",
    "input_tokenizer.fit_on_texts(totalX)\n",
    "#print(input_tokenizer.word_counts)\n",
    "encoded_docs = input_tokenizer.texts_to_matrix(totalX, mode='count')\n",
    "print(encoded_docs.shape)\n",
    "input_vocab_size = len(input_tokenizer.word_index) + 1\n",
    "print(\"input_vocab_size:\",input_vocab_size)\n",
    "totalX = np.array(pad_sequences(input_tokenizer.texts_to_sequences(totalX)))\n",
    "# print(input_tokenizer.word_counts)\n",
    "# print(t.document_count)\n",
    "# print(t.word_index)\n",
    "# print(t.word_docs)\n",
    "# print(totalX.counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten\n",
    "nn = Sequential()\n",
    "nn.add(Dense(10, activation=\"relu\", input_shape=(17601,)))\n",
    "#nn.add(Flatten())\n",
    "# nn.Flatten()\n",
    "nn.add(Dense(5,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def softmax(z):\n",
    "    z_exp = [math.exp(i) for i in z]\n",
    "    sum_z_exp = sum(z_exp)\n",
    "    return [i / sum_z_exp for i in z_exp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sarvat/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 900 samples, validate on 100 samples\n",
      "Epoch 1/5\n",
      "592/900 [==================>...........] - ETA: 4s - loss: 0.5729 - acc: 0.7439 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sarvat/.local/lib/python3.6/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.134082). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900/900 [==============================] - 9s 10ms/step - loss: 0.5161 - acc: 0.7747 - val_loss: 0.3260 - val_acc: 0.8340\n",
      "Epoch 2/5\n",
      "900/900 [==============================] - 0s 365us/step - loss: 0.2361 - acc: 0.8444 - val_loss: 0.1504 - val_acc: 0.8640\n",
      "Epoch 3/5\n",
      "900/900 [==============================] - 0s 261us/step - loss: 0.0323 - acc: 0.8564 - val_loss: 0.0153 - val_acc: 0.8660\n",
      "Epoch 4/5\n",
      "900/900 [==============================] - 0s 260us/step - loss: -0.1600 - acc: 0.8769 - val_loss: -0.0800 - val_acc: 0.8680\n",
      "Epoch 5/5\n",
      "900/900 [==============================] - 0s 223us/step - loss: -0.3212 - acc: 0.8878 - val_loss: -0.1437 - val_acc: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2aab18d240>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(np.array(encoded_docs), np.array(ranking), batch_size=16, epochs=5,\n",
    "          verbose=1, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
